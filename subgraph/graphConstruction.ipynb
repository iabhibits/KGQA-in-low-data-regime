{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/abhishek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import nltk\n",
    "import json\n",
    "# print('NLTK Version: %s' % (nltk.__version__))\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "nltk_stopwords += [\"like\", \"gone\", \"did\", \"going\", \"would\", \"could\", \"get\", \"in\", \"up\", \"may\", \"wanter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"paths.cfg\")\n",
    "\n",
    "cpnet = None\n",
    "concept2id = None\n",
    "relation2id = None\n",
    "id2relation = None\n",
    "id2concept = None\n",
    "blacklist = set([\"uk\", \"us\", \"take\", \"make\", \"object\", \"person\", \"people\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"paths.cfg\")\n",
    "\n",
    "cpnet = None\n",
    "concept2id = None\n",
    "relation2id = None\n",
    "id2relation = None\n",
    "id2concept = None\n",
    "blacklist = set([\"uk\", \"us\", \"take\", \"make\", \"object\", \"person\", \"people\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources():\n",
    "    global concept2id, relation2id, id2relation, id2concept\n",
    "    concept2id = {}\n",
    "    id2concept = {}\n",
    "    with open(config[\"paths\"][\"concept_vocab\"], \"r\", encoding=\"utf8\") as f:\n",
    "        for w in f.readlines():\n",
    "            concept2id[w.strip()] = len(concept2id)\n",
    "            id2concept[len(id2concept)] = w.strip()\n",
    "\n",
    "    print(\"concept2id done\")\n",
    "    id2relation = {}\n",
    "    relation2id = {}\n",
    "    with open(config[\"paths\"][\"relation_vocab\"], \"r\", encoding=\"utf8\") as f:\n",
    "        for w in f.readlines():\n",
    "            id2relation[len(id2relation)] = w.strip()\n",
    "            relation2id[w.strip()] = len(relation2id)\n",
    "    print(\"relation2id done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept2id done\n",
      "relation2id done\n"
     ]
    }
   ],
   "source": [
    "load_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cpnet():\n",
    "    global concept2id, relation2id, id2relation, id2concept, blacklist\n",
    "    load_resources()\n",
    "    graph = nx.MultiDiGraph()\n",
    "    with open(config[\"paths\"][\"conceptnet_en\"], \"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        def not_save(cpt):\n",
    "            if cpt in blacklist:\n",
    "                return True\n",
    "            for t in cpt.split(\"_\"):\n",
    "                if t in nltk_stopwords:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        for line in tqdm(lines, desc=\"saving to graph\"):\n",
    "            ls = line.strip().split('\\t')\n",
    "            rel = relation2id[ls[0]]\n",
    "            subj = concept2id[ls[1]]\n",
    "            obj = concept2id[ls[2]]\n",
    "            weight = float(ls[3])\n",
    "            if id2relation[rel] == \"hascontext\":\n",
    "                continue\n",
    "            if not_save(ls[1]) or not_save(ls[2]):\n",
    "                continue\n",
    "            if id2relation[rel] == \"relatedto\" or id2relation[rel] == \"antonym\":\n",
    "                weight -= 0.3\n",
    "                # continue\n",
    "            if subj == obj: # delete loops\n",
    "                continue\n",
    "            weight = 1+float(math.exp(1-weight))\n",
    "            graph.add_edge(subj, obj, rel=rel, weight=weight)\n",
    "            graph.add_edge(obj, subj, rel=rel+len(relation2id), weight=weight)\n",
    "\n",
    "\n",
    "    nx.write_gpickle(graph, config[\"paths\"][\"conceptnet_en_graph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_cpnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpnet():\n",
    "    global cpnet,concept2id, relation2id, id2relation, id2concept, cpnet_simple\n",
    "    print(\"loading cpnet....\")\n",
    "    cpnet = nx.read_gpickle(config[\"paths\"][\"conceptnet_en_graph\"])\n",
    "    print(\"Done\")\n",
    "\n",
    "    cpnet_simple = nx.Graph()\n",
    "    for u, v, data in cpnet.edges(data=True):\n",
    "        w = data['weight'] if 'weight' in data else 1.0\n",
    "        if cpnet_simple.has_edge(u, v):\n",
    "            cpnet_simple[u][v]['weight'] += w\n",
    "        else:\n",
    "            cpnet_simple.add_edge(u, v, weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge(src_concept, tgt_concept):\n",
    "    global cpnet, concept2id, relation2id, id2relation, id2concept\n",
    "    rel_list = cpnet[src_concept][tgt_concept]\n",
    "    # tmp = [rel_list[item][\"weight\"] for item in rel_list]\n",
    "    # s = tmp.index(min(tmp))\n",
    "    # rel = rel_list[s][\"rel\"]\n",
    "    return list(set([rel_list[item][\"rel\"] for item in rel_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths(source, target, ifprint = False):\n",
    "    try:\n",
    "        global cpnet, concept2id, relation2id, id2relation, id2concept, cpnet_simple\n",
    "        s = concept2id[source]\n",
    "        t = concept2id[target]\n",
    "\n",
    "        # try:\n",
    "        #     lenth, path = nx.bidirectional_dijkstra(cpnet, source=s, target=t, weight=\"weight\")\n",
    "        #     # print(lenth)\n",
    "        #     print(path)\n",
    "        # except nx.NetworkXNoPath:\n",
    "        #     print(\"no path\")\n",
    "        # paths = [path]\n",
    "\n",
    "        if s not in cpnet_simple.nodes() or t not in cpnet_simple.nodes():\n",
    "            return\n",
    "        # paths =\n",
    "        all_path = []\n",
    "        all_path_set = set()\n",
    "\n",
    "        for max_len in range(1, 3):\n",
    "            for p in nx.all_simple_paths(cpnet_simple, source=s, target=t, cutoff=max_len):\n",
    "                path_str = \"-\".join([str(c) for c in p])\n",
    "                if path_str not in all_path_set:\n",
    "                    all_path_set.add(path_str)\n",
    "                    all_path.append(p)\n",
    "                if len(all_path) >= 3:  # top shortest 300 paths\n",
    "                    break\n",
    "            if len(all_path) >= 3:  # top shortest 300 paths\n",
    "                break\n",
    "\n",
    "        # all_path = [[int(c) for c in p.split(\"-\")] for p in list(set([\"-\".join([str(c) for c in p]) for p in all_path]))]\n",
    "        # print(len(all_path))\n",
    "        all_path.sort(key=len, reverse=False)\n",
    "        pf_res = []\n",
    "        for p in all_path:\n",
    "            # print([id2concept[i] for i in p])\n",
    "            rl = []\n",
    "            for src in range(len(p) - 1):\n",
    "                src_concept = p[src]\n",
    "                tgt_concept = p[src + 1]\n",
    "\n",
    "                rel_list = get_edge(src_concept, tgt_concept)\n",
    "                rl.append(rel_list)\n",
    "                if ifprint:\n",
    "                    rel_list_str = []\n",
    "                    for rel in rel_list:\n",
    "                        if rel < len(id2relation):\n",
    "                            rel_list_str.append(id2relation[rel])\n",
    "                        else:\n",
    "                            rel_list_str.append(id2relation[rel - len(id2relation)]+\"*\")\n",
    "                    print(id2concept[src_concept], \"-[%s]-> \" %(\"/\".join(rel_list_str)), end=\"\")\n",
    "                    if src + 1 == len(p) - 1:\n",
    "                        print(id2concept[tgt_concept], end=\"\")\n",
    "            if ifprint:\n",
    "                print()\n",
    "\n",
    "            pf_res.append({\"path\": p, \"rel\": rl})\n",
    "        return pf_res\n",
    "    except:\n",
    "        path_ = []\n",
    "        return path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(example, batch_id=-1):\n",
    "    pf = []\n",
    "    #output_path = filename + \".%d\" % (batch_id) + \".pf\"\n",
    "    import os\n",
    "    if os.path.exists(output_path):\n",
    "        print(output_path + \" exists. Skip!\")\n",
    "        return\n",
    "\n",
    "    load_resources()\n",
    "    load_cpnet()\n",
    "    with open(filename, 'r') as fp:\n",
    "        mcp_data = json.load(fp)\n",
    "        mcp_data = list(np.array_split(mcp_data, 100)[batch_id])\n",
    "\n",
    "        for item in tqdm(mcp_data, desc=\"batch_id: %d \"%batch_id):\n",
    "            acs = item[\"ac\"]\n",
    "            qcs = item[\"qc\"]\n",
    "            pfr_qa = []  # path finding results\n",
    "            for ac in acs:\n",
    "                for qc in qcs:\n",
    "                    pf_res = find_paths(qc, ac)\n",
    "                    pfr_qa.append({\"ac\":ac, \"qc\":qc, \"pf_res\":pf_res})\n",
    "            pf.append(pfr_qa)\n",
    "\n",
    "    with open(output_path, 'w') as fi:\n",
    "        json.dump(pf, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cpnet....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "load_cpnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palm -[isa]-> area -[relatedto*]-> dry\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "find_paths(\"palm\", \"dry\", ifprint=True)\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/ob_data/train/ob_concepts_train_final.mcp\",'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = data[0:10]\n",
    "len(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ex[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sent': ' ',\n",
       "  'option': 'The sun is responsible for puppies learning new tricks',\n",
       "  'premise': ['youngs',\n",
       "   'of_love',\n",
       "   'difference',\n",
       "   'seem',\n",
       "   'stench',\n",
       "   'enough',\n",
       "   'wanter',\n",
       "   'heart',\n",
       "   'tell',\n",
       "   'waye',\n",
       "   'young_and',\n",
       "   'way',\n",
       "   'long',\n",
       "   'old_plants',\n",
       "   'independence',\n",
       "   'signing',\n",
       "   'children_at',\n",
       "   'childs',\n",
       "   'real',\n",
       "   'point',\n",
       "   'great',\n",
       "   'imagine',\n",
       "   'storied',\n",
       "   'tell_me',\n",
       "   'planting',\n",
       "   'childe',\n",
       "   'child',\n",
       "   'plant',\n",
       "   'hear',\n",
       "   'getting_enough',\n",
       "   'may',\n",
       "   'shade',\n",
       "   'showest',\n",
       "   'grows',\n",
       "   'young',\n",
       "   'get',\n",
       "   'plants_and',\n",
       "   'may_be',\n",
       "   'and_children',\n",
       "   'hears',\n",
       "   'size',\n",
       "   'hearting',\n",
       "   'low',\n",
       "   'wantest',\n",
       "   'get_old',\n",
       "   'old',\n",
       "   'death',\n",
       "   'enjoyest',\n",
       "   'show',\n",
       "   'want_to',\n",
       "   'inspire',\n",
       "   'giant',\n",
       "   'expert',\n",
       "   'consider',\n",
       "   'exist',\n",
       "   'story',\n",
       "   'time',\n",
       "   'sunflow',\n",
       "   'age',\n",
       "   'loud',\n",
       "   'much',\n",
       "   'food',\n",
       "   'signest',\n",
       "   'shaded',\n",
       "   'grow',\n",
       "   'sign',\n",
       "   'existest',\n",
       "   'grown',\n",
       "   'love',\n",
       "   'too_much',\n",
       "   'start',\n",
       "   'grow_up',\n",
       "   'rightest',\n",
       "   'younge',\n",
       "   'actively',\n",
       "   'olde',\n",
       "   'storye',\n",
       "   'right',\n",
       "   'get_child',\n",
       "   'all_children',\n",
       "   'too_long',\n",
       "   'enjoy'],\n",
       "  'hypothesis': ['childs',\n",
       "   'grow',\n",
       "   'grows',\n",
       "   'get',\n",
       "   'grown',\n",
       "   'childe',\n",
       "   'olde',\n",
       "   'child',\n",
       "   'child_grows_up',\n",
       "   'grow_up',\n",
       "   'get_old',\n",
       "   'children_grow_up',\n",
       "   'old'],\n",
       "  'ans': ['being_responsible',\n",
       "   'puppy',\n",
       "   'responsible_for',\n",
       "   'sun_is',\n",
       "   'sun',\n",
       "   'sunned',\n",
       "   'learn',\n",
       "   'learn_new',\n",
       "   'newe',\n",
       "   'trick',\n",
       "   'learns',\n",
       "   'new',\n",
       "   'learn_new_tricks',\n",
       "   'be_responsible_for',\n",
       "   'learning',\n",
       "   'responsible',\n",
       "   'suns']}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youngs',\n",
       " 'of_love',\n",
       " 'difference',\n",
       " 'seem',\n",
       " 'stench',\n",
       " 'enough',\n",
       " 'wanter',\n",
       " 'heart',\n",
       " 'tell',\n",
       " 'waye',\n",
       " 'young_and',\n",
       " 'way',\n",
       " 'long',\n",
       " 'old_plants',\n",
       " 'independence',\n",
       " 'signing',\n",
       " 'children_at',\n",
       " 'childs',\n",
       " 'real',\n",
       " 'point',\n",
       " 'great',\n",
       " 'imagine',\n",
       " 'storied',\n",
       " 'tell_me',\n",
       " 'planting',\n",
       " 'childe',\n",
       " 'child',\n",
       " 'plant',\n",
       " 'hear',\n",
       " 'getting_enough',\n",
       " 'may',\n",
       " 'shade',\n",
       " 'showest',\n",
       " 'grows',\n",
       " 'young',\n",
       " 'get',\n",
       " 'plants_and',\n",
       " 'may_be',\n",
       " 'and_children',\n",
       " 'hears',\n",
       " 'size',\n",
       " 'hearting',\n",
       " 'low',\n",
       " 'wantest',\n",
       " 'get_old',\n",
       " 'old',\n",
       " 'death',\n",
       " 'enjoyest',\n",
       " 'show',\n",
       " 'want_to',\n",
       " 'inspire',\n",
       " 'giant',\n",
       " 'expert',\n",
       " 'consider',\n",
       " 'exist',\n",
       " 'story',\n",
       " 'time',\n",
       " 'sunflow',\n",
       " 'age',\n",
       " 'loud',\n",
       " 'much',\n",
       " 'food',\n",
       " 'signest',\n",
       " 'shaded',\n",
       " 'grow',\n",
       " 'sign',\n",
       " 'existest',\n",
       " 'grown',\n",
       " 'love',\n",
       " 'too_much',\n",
       " 'start',\n",
       " 'grow_up',\n",
       " 'rightest',\n",
       " 'younge',\n",
       " 'actively',\n",
       " 'olde',\n",
       " 'storye',\n",
       " 'right',\n",
       " 'get_child',\n",
       " 'all_children',\n",
       " 'too_long',\n",
       " 'enjoy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]['premise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent': ' ', 'option': 'D', 'premise': ['sun', 'special', 'new', 'performs', 'learning', 'suns', 'deal', 'trick', 'student', 'find', 'learns', 'parroting', 'skille', 'great_deal_of', 'world', 'cockatoo', 'finding', 'front_of', 'responsible', 'respond', 'sure', 'evens', 'conure', 'great', 'maked', 'alert', 'ostrich', 'learn_new', 'turn', 'skill', 'and_love', 'in_front', 'perform_in', 'adept', 'live', 'end_of', 'grows', 'nearly', 'telescope', 'throughout', 'artisan_who', 'capable', 'bring', 'old', 'always', 'puppy', 'training', 'koto', 'technique', 'new_family', 'dog', 'beak', 'even', 'learn_how_to', 'mirror', 'great_deal', 'parrot', 'know', 'well', 'learn_new_tricks', 'probleme', 'family', 'dealest', 'adepts', 'willing', 'every', 'perform', 'old_dog', 'object', 'front', 'performing_in_front_of', 'in_front_of', 'knowing_yourself', 'grow', 'learn', 'sunned', 'grown', 'love', 'mirrored', 'arise', 'artisan', 'breeder', 'kotos', 'make_sure', 'clawing', 'for_learning', 'ferret', 'learn_how', 'objected', 'objectest', 'wells', 'question', 'olde', 'knowed', 'cockatoos', 'end', 'turn_to', 'guarantee', 'newe', 'claw', 'beaks', 'knows', 'arisen', 'problem'], 'hypothesis': ['puppy', 'learn', 'sun_is', 'sun', 'sunned', 'learn_new', 'new', 'be_responsible_for', 'learning', 'suns', 'being_responsible', 'trick', 'responsible_for', 'learns', 'learn_new_tricks', 'newe', 'responsible'], 'ans': ['d']}\n",
      "5\n",
      "{'sent': ' ', 'option': 'The sun is responsible for puppies learning new tricks', 'premise': ['youngs', 'of_love', 'difference', 'seem', 'stench', 'enough', 'wanter', 'heart', 'tell', 'waye', 'young_and', 'way', 'long', 'old_plants', 'independence', 'signing', 'children_at', 'childs', 'real', 'point', 'great', 'imagine', 'storied', 'tell_me', 'planting', 'childe', 'child', 'plant', 'hear', 'getting_enough', 'may', 'shade', 'showest', 'grows', 'young', 'get', 'plants_and', 'may_be', 'and_children', 'hears', 'size', 'hearting', 'low', 'wantest', 'get_old', 'old', 'death', 'enjoyest', 'show', 'want_to', 'inspire', 'giant', 'expert', 'consider', 'exist', 'story', 'time', 'sunflow', 'age', 'loud', 'much', 'food', 'signest', 'shaded', 'grow', 'sign', 'existest', 'grown', 'love', 'too_much', 'start', 'grow_up', 'rightest', 'younge', 'actively', 'olde', 'storye', 'right', 'get_child', 'all_children', 'too_long', 'enjoy'], 'hypothesis': ['childs', 'grow', 'grows', 'get', 'grown', 'childe', 'olde', 'child', 'child_grows_up', 'grow_up', 'get_old', 'children_grow_up', 'old'], 'ans': ['being_responsible', 'puppy', 'responsible_for', 'sun_is', 'sun', 'sunned', 'learn', 'learn_new', 'newe', 'trick', 'learns', 'new', 'learn_new_tricks', 'be_responsible_for', 'learning', 'responsible', 'suns']}\n",
      "5\n",
      "{'sent': ' ', 'option': 'The sun is responsible for children growing up and getting old', 'premise': ['pyramid', 'shortens', 'cools', 'drier', 'often_used', 'tulip', 'serve', 'dry', 'lifespan', 'countable', 'somethinge', 'treatment', 'use', 'pyramiding', 'main', 'factor', 'cut_flower', 'especially', 'aid', 'instance', 'ray', 'flowers_in', 'hots', 'primarily', 'shelter', 'wired', 'prevent', 'shortenest', 'hung', 'use_to', 'placing', 'sheltered', 'be_due', 'direct', 'finish', 'lifespans', 'alongside', 'put', 'hot', 'hotter', 'premature', 'dried_flower', 'photosynthesise', 'limit', 'latter', 'vase', 'insufficient', 'hang', 'arrangement', 'shorten', 'fillest', 'due_to', 'wired_into', 'shelterer', 'opens', 'stem', 'limited', 'filling', 'designing', 'basket', 'cool', 'design', 'flower', 'wire', 'sometimes_wire', 'hanging_basket', 'open', 'sunlight', 'container', 'showpiece', 'photosynthesis', 'wilt', 'open_container', 'holds', 'aids', 'life', 'location', 'decorative', 'ray_flower', 'cut', 'stems', 'fill', 'often', 'noun', 'due', 'hold', 'also'], 'hypothesis': ['flower', 'wilt', 'vase'], 'ans': ['sun_is', 'sun', 'be_responsible_for', 'suns', 'being_responsible', 'responsible_for', 'responsible', 'childs', 'grow', 'sunned', 'grown', 'childe', 'child', 'child_grows_up', 'grow_up', 'children_grow_up', 'grows', 'get', 'olde', 'for_child', 'get_old', 'old']}\n",
      "5\n",
      "{'sent': ' ', 'option': 'The sun is responsible for flowers wilting in a vase', 'premise': ['usually', 'bloom', 'aloe', 'pepper_plant', 'drier', 'closed', 'viewest', 'tulip', 'keep', 'dry', 'continue', 'alternate', 'home', 'pepper', 'lose', 'meaned', 'occur', 'close_to', 'planting', 'backest', 'pressured', 'of_plants', 'turgor', 'plant', 'millet_plant', 'balsams', 'may', 'quickly', 'developest', 'homing', 'showest', 'class', 'soil', 'balsam', 'first', 'bright', 'spur', 'means', 'keepest', 'relative', 'wide_view', 'trim', 'especially', 'millet', 'collapse', 'oxalate', 'sprouting', 'content', 'different', 'closer', 'bulbed', 'balsamed', 'increase', 'plant_eventually', 'show', 'room_and', 'presentest', 'mean', 'fig', 'well', 'classing', 'probleme', 'spurred', 'sprout', 'wide', 'back', 'tulsi', 'views', 'pressure', 'millets', 'strong', 'show_to', 'spurs', 'present', 'bulb', 'plant_increasing', 'wides', 'view', 'close', 'blooms', 'brighter', 'room', 'and_plant', 'eventually', 'wells', 'coefficient', 'n', 'brights', 'leave', 'aloes', 'at_first', 'unchecked', 'develop', 'problem'], 'hypothesis': ['bloom', 'sprouting', 'planting', 'sprout', 'plant', 'blooms'], 'ans': ['being_responsible', 'responsible_for', 'sun_is', 'sun', 'sunned', 'vase', 'flower', 'wilt', 'be_responsible_for', 'responsible', 'suns', 'for_flowers']}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for e in ex:\n",
    "    for item in e:\n",
    "        print(item[0])\n",
    "        print(len(item[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': [3461, 2210, 9841], 'rel': [[15], [17]]},\n",
       " {'path': [3461, 28366, 9841], 'rel': [[18], [32]]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_paths('sun','puppy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "pf = []\n",
    "for e in tqdm(ex):\n",
    "    pfr_gpre = []  # path finding results\n",
    "    pfr_hyp = []\n",
    "    for item in e:\n",
    "        gpre = item[0][\"premise\"]\n",
    "        ghyp = item[0][\"hypothesis\"]\n",
    "        ans = item[0][\"ans\"]\n",
    "        for pre in gpre:\n",
    "            for ac in ans:\n",
    "                gpf_res = find_paths(pre, ac)\n",
    "                #print(pf_res)\n",
    "                pfr_gpre.append({\"pre\":pre, \"ac\":ac, \"path\":gpf_res})\n",
    "        for hyp in ghyp:\n",
    "            for answer in ans:\n",
    "                hpf_res = find_paths(hyp,answer)\n",
    "                pfr_hyp.append({\"hyp\":hyp,\"hac\":answer, \"path\":hpf_res})\n",
    "        combine =[pfr_gpre,pfr_hyp]\n",
    "        pf.append(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pf[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pf[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_arc(data,start,end):\n",
    "    data = data[start:end]\n",
    "    pf = []\n",
    "    for item in tqdm(ex):\n",
    "        gpre = item[\"premise\"]\n",
    "        ghyp = item[\"hypothesis\"]\n",
    "        ans = item[\"ans\"]\n",
    "        pfr_gpre = []  # path finding results\n",
    "        pfr_hyp = []\n",
    "        for pre in gpre:\n",
    "            for ac in ans:\n",
    "                gpf_res = find_paths(pre, ac)\n",
    "                #print(pf_res)\n",
    "                pfr_gpre.append({\"pre\":pre, \"ac\":ac, \"path\":gpf_res})\n",
    "        for hyp in ghyp:\n",
    "            for answer in ans:\n",
    "                hpf_res = find_paths(hyp,answer)\n",
    "                pfr_hyp.append({\"hyp\":hyp,\"hac\":answer, \"path\":hpf_res})\n",
    "        combine =[pfr_gpre,pfr_hyp]\n",
    "        pf.append(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsbeautifier\n",
    "opts = jsbeautifier.default_options()\n",
    "opts.indent_size = 2\n",
    "\n",
    "with open(\"example.mcp\",\"w\") as fp:\n",
    "    fp.write(jsbeautifier.beautify(json.dumps(pf), opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
