{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import configparser\n",
    "\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import os\n",
    "from os import sys, path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"paths.cfg\")\n",
    "\n",
    "\n",
    "cpnet = None\n",
    "cpnet_simple = None\n",
    "concept2id = None\n",
    "relation2id = None\n",
    "id2relation = None\n",
    "id2concept = None\n",
    "concept_embs = None\n",
    "relation_embs = None\n",
    "mcp_py_filenmae = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources(method):\n",
    "\n",
    "    global concept2id, id2concept, concept_embs, relation2id, id2relation, relation_embs\n",
    "    concept2id = {}\n",
    "    id2concept = {}\n",
    "    with open(config[\"paths\"][\"concept_vocab\"], \"r\", encoding=\"utf8\") as f:\n",
    "        for w in f.readlines():\n",
    "            concept2id[w.strip()] = len(concept2id)\n",
    "            id2concept[len(id2concept)] = w.strip()\n",
    "\n",
    "    print(\"concept2id done\")\n",
    "\n",
    "    concept_embs = np.load(\"../embeddings/openke_data/embs/glove_initialized/glove.transe.sgd.ent.npy\")\n",
    "\n",
    "    print(\"concept_embs done\")\n",
    "\n",
    "    if method == \"triple_cls\":\n",
    "\n",
    "        relation2id = {}\n",
    "        id2relation = {}\n",
    "\n",
    "        with open(config[\"paths\"][\"relation_vocab\"], \"r\", encoding=\"utf8\") as f:\n",
    "            for w in f.readlines():\n",
    "                relation2id[w.strip()] = len(relation2id)\n",
    "                id2relation[len(id2relation)] = w.strip()\n",
    "\n",
    "        print(\"relation2id done\")\n",
    "\n",
    "        relation_embs = np.load(\"../embeddings/openke_data/embs/glove_initialized/glove.transe.sgd.rel.npy\")\n",
    "\n",
    "        print(\"relation_embs done\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanila_score_triple(h, t, r):\n",
    "\n",
    "    # return np.linalg.norm(t-h-r)\n",
    "    return (1 + 1 - spatial.distance.cosine(r, t - h)) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanila_score_triples(concept_id, relation_id):\n",
    "\n",
    "\n",
    "    global relation_embs, concept_embs, id2relation, id2concept\n",
    "\n",
    "    concept = concept_embs[concept_id]\n",
    "    relation = []\n",
    "\n",
    "    flag = []\n",
    "    for i in range(len(relation_id)):\n",
    "\n",
    "        embs = []\n",
    "        l_flag = []\n",
    "\n",
    "        if 0 in relation_id[i] and 17 not in relation_id[i]:\n",
    "            relation_id[i].append(17)\n",
    "        elif 17 in relation_id[i] and 0 not in relation_id[i]:\n",
    "            relation_id[i].append(0)\n",
    "\n",
    "        if 15 in relation_id[i] and 32 not in relation_id[i]:\n",
    "            relation_id[i].append(32)\n",
    "        elif 32 in relation_id[i] and 15 not in relation_id[i]:\n",
    "            relation_id[i].append(15)\n",
    "\n",
    "\n",
    "        for j in range(len(relation_id[i])):\n",
    "\n",
    "            if relation_id[i][j] >= 17:\n",
    "\n",
    "                score = vanila_score_triple(concept[i + 1], concept[i], relation_embs[relation_id[i][j] - 17])\n",
    "\n",
    "                print(\"%s\\tr-%s\\t%s\" % (id2concept[concept_id[i]], id2relation[relation_id[i][j] - 17], id2concept[concept_id[i + 1]]))\n",
    "                print(\"Likelihood: \" + str(score) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                score = vanila_score_triple(concept[i], concept[i + 1], relation_embs[relation_id[i][j]])\n",
    "\n",
    "                print(\"%s\\t%s\\t%s\" % (id2concept[concept_id[i]], id2relation[relation_id[i][j]], id2concept[concept_id[i + 1]]))\n",
    "                print(\"Likelihood: \" + str(score) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_triple(h, t, r, flag):\n",
    "\n",
    "    res = -10\n",
    "\n",
    "    for i in range(len(r)):\n",
    "        if flag[i]:\n",
    "            temp_h, temp_t = t, h\n",
    "        else:\n",
    "            temp_h, temp_t = h, t\n",
    "\n",
    "        # result  = (cosine_sim + 1) / 2\n",
    "        res = max(res, (1 + 1 - spatial.distance.cosine(r[i], temp_t - temp_h)) / 2)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_triples(concept_id, relation_id, debug=False):\n",
    "\n",
    "    global relation_embs, concept_embs, id2relation, id2concept\n",
    "\n",
    "    concept = concept_embs[concept_id]\n",
    "    relation = []\n",
    "\n",
    "    flag = []\n",
    "    for i in range(len(relation_id)):\n",
    "\n",
    "        embs = []\n",
    "        l_flag = []\n",
    "\n",
    "        if 0 in relation_id[i] and 17 not in relation_id[i]:\n",
    "            relation_id[i].append(17)\n",
    "        elif 17 in relation_id[i] and 0 not in relation_id[i]:\n",
    "            relation_id[i].append(0)\n",
    "\n",
    "        if 15 in relation_id[i] and 32 not in relation_id[i]:\n",
    "            relation_id[i].append(32)\n",
    "        elif 32 in relation_id[i] and 15 not in relation_id[i]:\n",
    "            relation_id[i].append(15)\n",
    "\n",
    "        for j in range(len(relation_id[i])):\n",
    "\n",
    "            if relation_id[i][j] >= 17:\n",
    "                embs.append(relation_embs[relation_id[i][j] - 17])\n",
    "                l_flag.append(1)\n",
    "\n",
    "            else:\n",
    "                embs.append(relation_embs[relation_id[i][j]])\n",
    "                l_flag.append(0)\n",
    "\n",
    "\n",
    "        relation.append(embs)\n",
    "\n",
    "        flag.append(l_flag)\n",
    "\n",
    "\n",
    "    res = 1\n",
    "\n",
    "    for i in range(concept.shape[0] - 1):\n",
    "        h = concept[i]\n",
    "        t = concept[i + 1]\n",
    "        score = score_triple(h, t, relation[i], flag[i])\n",
    "\n",
    "        res *= score\n",
    "\n",
    "    if debug:\n",
    "        print(\"Num of concepts:\")\n",
    "        print(len(concept_id))\n",
    "\n",
    "\n",
    "        to_print = \"\"\n",
    "\n",
    "        for i in range(concept.shape[0] - 1):\n",
    "\n",
    "            h = id2concept[concept_id[i]]\n",
    "\n",
    "            to_print += h + \"\\t\"\n",
    "            for rel in relation_id[i]:\n",
    "                if rel >= 17:\n",
    "\n",
    "                    # 'r-' means reverse\n",
    "                    to_print += (\"r-\" + id2relation[rel - 17] + \"/  \")\n",
    "                else:\n",
    "                    to_print += id2relation[rel] + \"/  \"\n",
    "\n",
    "\n",
    "        to_print += id2concept[concept_id[-1]]\n",
    "        print(to_print)\n",
    "\n",
    "        print(\"Likelihood: \" + str(res) + \"\\n\")\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_per_qa(acs, qcs, pooling=\"mean\"):\n",
    "    '''\n",
    "    calculate the context embedding for each q-a statement in terms of mentioned concepts\n",
    "    '''\n",
    "\n",
    "    global cpnet, concept2id, relation2id, id2relation, id2concept, cpnet_simple, concept_embs\n",
    "    for i in range(len(acs)):\n",
    "        acs[i] = concept2id[acs[i]]\n",
    "\n",
    "    for i in range(len(qcs)):\n",
    "        qcs[i] = concept2id[qcs[i]]\n",
    "\n",
    "    concept_ids = np.asarray(list(set(qcs) | set(acs)), dtype=int)\n",
    "    concept_context_emb = np.mean(concept_embs[concept_ids], axis=0) if pooling==\"mean\" else np.maximum(concept_embs[concept_ids])\n",
    "\n",
    "    return concept_context_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_scoring(path, context):\n",
    "\n",
    "    global concept_embs\n",
    "\n",
    "    path_concepts = concept_embs[path]\n",
    "\n",
    "\n",
    "    # cosine distance, the smaller the more alike\n",
    "\n",
    "    cosine_dist = np.apply_along_axis(spatial.distance.cosine, 1, path_concepts, context)\n",
    "    cosine_sim = 1 - cosine_dist\n",
    "    if len(path) > 2:\n",
    "        return min(cosine_sim[1:-1]) # the minimum of the cos sim of the middle concepts\n",
    "    else:\n",
    "        return 1.0 # the source and target of the paths are qa concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_context_emb(pooling=\"mean\", filename =\"\"):\n",
    "    global mcp_py_filenmae\n",
    "    mcp_py_filenmae = filename + \".\" + pooling + \".npy\"\n",
    "    if os.path.exists(mcp_py_filenmae):\n",
    "        print(mcp_py_filenmae, \"exists!\")\n",
    "        return\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        mcp = json.load(f)\n",
    "\n",
    "    embs = []\n",
    "\n",
    "    for s in tqdm(mcp, desc=\"Computing concept-context embedding..\"):\n",
    "        qcs = s[\"qc\"]\n",
    "        acs = s[\"ac\"]\n",
    "\n",
    "        embs.append(context_per_qa(acs=acs, qcs=qcs, pooling=pooling))\n",
    "\n",
    "\n",
    "    embs = np.asarray(embs)\n",
    "    print(\"output_path: \" + mcp_py_filenmae)\n",
    "    np.save(mcp_py_filenmae, embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_paths(filename, score_filename, method, debug=False, debug_range=None):\n",
    "\n",
    "    global id2concept, mcp_py_filenmae\n",
    "\n",
    "    print(\"Loading paths\")\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        input = pickle.load(f)\n",
    "\n",
    "    print(\"Paths loaded\")\n",
    "\n",
    "    if not method == \"triple_cls\":\n",
    "\n",
    "        print(\"Loading context embeddings\")\n",
    "\n",
    "        context_embs = np.load(mcp_py_filenmae)\n",
    "\n",
    "        print(\"Loaded\")\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    if debug:\n",
    "        a, b =debug_range\n",
    "        input = input[a:b]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for index, qa_pairs in tqdm(enumerate(input), desc=\"Scoring the paths\", total=len(input)):\n",
    "        statemetn_scores = []\n",
    "        for qa_idx, qas in enumerate(qa_pairs):\n",
    "            statement_paths = qas[\"pf_res\"]\n",
    "\n",
    "            if statement_paths is not None:\n",
    "\n",
    "                if not method == \"triple_cls\":\n",
    "\n",
    "                    context_emb = context_embs[index]\n",
    "\n",
    "                path_scores = []\n",
    "                for pf_idx, item in enumerate(statement_paths):\n",
    "\n",
    "                    assert len(item[\"path\"]) > 1\n",
    "                    # vanila_score_triples(concept_id=item[\"path\"], relation_id=item[\"rel\"])\n",
    "\n",
    "                    if not method == \"triple_cls\":\n",
    "                        score = path_scoring(path=item[\"path\"], context=context_emb)\n",
    "\n",
    "                    else:\n",
    "                        score = score_triples(concept_id=item[\"path\"], relation_id=item[\"rel\"], debug=debug)\n",
    "                    path_scores.append(score)\n",
    "                statemetn_scores.append(path_scores)\n",
    "            else:\n",
    "                statemetn_scores.append(None)\n",
    "\n",
    "        all_scores.append(statemetn_scores)\n",
    "\n",
    "\n",
    "\n",
    "    if not debug:\n",
    "\n",
    "        print(\"saving the path scores\")\n",
    "        with open(score_filename, 'wb') as fp:\n",
    "            pickle.dump(all_scores, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"triple_cls\" #\n",
    "mcp_file = \"../datasets/arc_data/arc_train_final.mcp\"\n",
    "ori_pckle_file = \"../datasets/csqa_new/%s_rand_split.jsonl.statements.mcp.pf.pickle\"%flag\n",
    "scores_pckle_file = \"../datasets/csqa_new/%s_rand_split.jsonl.statements.mcp.pf.cls.scores.pickle\"%flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept2id done\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../embeddings/openke_data/embs/glove_initialized/glove.transe.sgd.ent.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ac97128fbe95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''to calculate the context embedding for qas'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mload_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6bdfb6aaba89>\u001b[0m in \u001b[0;36mload_resources\u001b[0;34m(method)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"concept2id done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mconcept_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../embeddings/openke_data/embs/glove_initialized/glove.transe.sgd.ent.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"concept_embs done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/QA/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../embeddings/openke_data/embs/glove_initialized/glove.transe.sgd.ent.npy'"
     ]
    }
   ],
   "source": [
    "'''to calculate the context embedding for qas'''\n",
    "\n",
    "load_resources(method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
